{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from wikitables import *\n",
    "import mwclient\n",
    "import mwparserfromhell as mwp\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "nested_dict = lambda: defaultdict(nested_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"wikitables\")\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# retrieve list of articles with tables in wikipedia\n",
    "# get 10 articles each from a-z with appeneded random letter to act as random sample of tables\n",
    "import string\n",
    "import random\n",
    "\n",
    "articles = list()\n",
    "site = mwclient.Site('en.wikipedia.org')\n",
    "\n",
    "# for letter in string.ascii_lowercase:\n",
    "#     counter = 0\n",
    "#     while (counter!=10):\n",
    "#         for page in site.allpages(filterredir='nonredirects', prefix=letter+random.choice(string.ascii_lowercase)):\n",
    "#             tables = mwp.parse(page.text()).filter_tags(matches=ftag('table'))\n",
    "#             if tables:\n",
    "#                 t = import_tables(page.name)\n",
    "#                 if t:\n",
    "#                     print(page.name)\n",
    "#                     articles.append(page.name)\n",
    "#                     counter+=1\n",
    "#                     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # save the articles with tables\n",
    "# import pickle\n",
    "\n",
    "# with open(\"articles.txt\", \"wb\") as fp:\n",
    "#     pickle.dump(articles, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the saved articles\n",
    "import pickle\n",
    "with open(\"articles.txt\", \"rb\") as fp:\n",
    "    articles = sorted(list(set(pickle.load(fp))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract tables and content needed for disambiguation/features\n",
    "# t = nested_dict()\n",
    "\n",
    "# for i in range(len(articles)):\n",
    "#   t[str(i)] = import_tables(articles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save the extracted tables\n",
    "# import pickle\n",
    "\n",
    "# # https://stackoverflow.com/a/26496899\n",
    "# def default_to_regular(d):\n",
    "#     if isinstance(d, defaultdict):\n",
    "#         d = {k: default_to_regular(v) for k, v in d.items()}\n",
    "#     return d\n",
    "\n",
    "# t = default_to_regular(t)\n",
    "\n",
    "# with open(\"tables.txt\", \"wb\") as fp:\n",
    "#      pickle.dump(t, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

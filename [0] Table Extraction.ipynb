{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from wikitables import *\n",
    "import mwclient\n",
    "import mwparserfromhell as mwp\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "nested_dict = lambda: defaultdict(nested_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"wikitables\")\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# retrieve list of articles with tables in wikipedia\n",
    "# get 10 articles each from a-z with appeneded random letter to act as random sample of tables\n",
    "import string\n",
    "import random\n",
    "\n",
    "articles = list()\n",
    "site = mwclient.Site('en.wikipedia.org')\n",
    "\n",
    "# for letter in string.ascii_lowercase:\n",
    "#     counter = 0\n",
    "#     while (counter!=10):\n",
    "#         for page in site.allpages(filterredir='nonredirects', prefix=letter+random.choice(string.ascii_lowercase)):\n",
    "#             tables = mwp.parse(page.text()).filter_tags(matches=ftag('table'))\n",
    "#             if tables:\n",
    "#                 t = import_tables(page.name)\n",
    "#                 if t:\n",
    "#                     print(page.name)\n",
    "#                     articles.append(page.name)\n",
    "#                     counter+=1\n",
    "#                     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # save the articles with tables\n",
    "# import pickle\n",
    "\n",
    "# with open(\"articles.txt\", \"wb\") as fp:\n",
    "#     pickle.dump(articles, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the saved articles\n",
    "import pickle\n",
    "with open(\"articles.txt\", \"rb\") as fp:\n",
    "    articles = set(pickle.load(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Am386\n",
      "Am386\n",
      "Ah! My Goddess (season 1)\n",
      "Ah! My Goddess (season 1)\n",
      "Am386\n",
      "Am386\n",
      "Af Chapman (ship)\n",
      "Afa, Corse-du-Sud\n",
      "Afa, Corse-du-Sud\n",
      "Ay! Catira Marmoleña\n",
      "Ay! Catira Marmoleña\n",
      "AzMarie Livingston\n",
      "Az Yet\n",
      "Az Yet\n",
      "Ar-Raniry State Islamic University\n",
      "Ar Angel Aviles\n",
      "Ar Hyd y Nos\n",
      "Ar Lan y Môr\n",
      "Ar Men\n",
      "Ar Men\n",
      "Ab 18\n",
      "Ab 18\n",
      "AwE naturalE\n",
      "AwE naturalE\n",
      "Ae Dil Hai Mushkil\n",
      "Ae Dil Hai Mushkil (song)\n",
      "Aechmea\n",
      "Aechmea chantinii\n",
      "Aechmea fasciata\n",
      "Aechmea recurvata\n",
      "Aechmophorus\n",
      "Aechmophorus\n",
      "As-Safira District\n",
      "As-Salam Al-Malaki Al-Urduni\n",
      "As-Salam Al-Malaki Al-Urduni\n",
      "Au, St. Gallen\n",
      "Au, St. Gallen\n",
      "Ap Lei Chau North (constituency)\n",
      "Apa Sherpa\n",
      "Apa Sherpa\n",
      "Av3k\n",
      "Av8er Explorer\n",
      "Av8er Limited\n",
      "Av8er Observer Light\n",
      "Av8er Orbiter\n",
      "Ava (2017 Iranian film)\n",
      "Ava 4A\n"
     ]
    }
   ],
   "source": [
    "# # add more articles\n",
    "\n",
    "new_articles = set()\n",
    "count = 0\n",
    "tdict = nested_dict()\n",
    "\n",
    "for letter in string.ascii_lowercase:\n",
    "    counter = 0\n",
    "    while (counter!=50):\n",
    "        for page in site.allpages(filterredir='nonredirects', prefix=letter+random.choice(string.ascii_lowercase)):\n",
    "            if page.name not in articles:\n",
    "                tables = mwp.parse(page.text()).filter_tags(matches=ftag('table'))\n",
    "                if tables:\n",
    "                    t = import_tables(page.name)\n",
    "                    if t:\n",
    "                        print(page.name)\n",
    "                        tdict[str(count)] = t\n",
    "                        new_articles.add(page.name)\n",
    "                        counter+=1\n",
    "                        count+=1\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_articles = sorted(list(new_articles))\n",
    "len(new_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # extract tables and content needed for disambiguation/features\n",
    "# t = nested_dict()\n",
    "\n",
    "# count = 0\n",
    "\n",
    "# for i in range(len(articles)):\n",
    "#     m = import_tables(articles[i])\n",
    "#     if m is not None:\n",
    "#         t[str(count)] = m\n",
    "#         count+=1\n",
    "        \n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save the extracted tables\n",
    "# import pickle\n",
    "\n",
    "# https://stackoverflow.com/a/26496899\n",
    "def default_to_regular(d):\n",
    "    if isinstance(d, defaultdict):\n",
    "        d = {k: default_to_regular(v) for k, v in d.items()}\n",
    "    return d\n",
    "\n",
    "# t = default_to_regular(t)\n",
    "\n",
    "# with open(\"tables.txt\", \"wb\") as fp:\n",
    "#      pickle.dump(t, fp)\n",
    "\n",
    "tdict = default_to_regular(tdict)\n",
    "\n",
    "with open(\"new_tables.txt\", \"wb\") as fp:\n",
    "     pickle.dump(tdict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
